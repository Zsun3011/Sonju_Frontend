import React, { useState, useEffect } from 'react';
import { View, Text, TouchableOpacity, Animated } from 'react-native';
import AudioRecorderPlayer from 'react-native-audio-recorder-player';
import { voiceAPI } from '../../api/voice';
import { useChat } from '../../store/ChatContext';
import { chatStyles as s } from '../../styles/ChatStyles';

const audioRecorderPlayer = new AudioRecorderPlayer();

export default function VoiceChatPage({ navigation }: any) {
  const { sendMessage } = useChat();
  const [isRecording, setIsRecording] = useState(false);
  const [audioPath, setAudioPath] = useState('');
  const pulseAnim = new Animated.Value(1);

  useEffect(() => {
    if (isRecording) {
      startPulseAnimation();
    }
  }, [isRecording]);

  const startPulseAnimation = () => {
    Animated.loop(
      Animated.sequence([
        Animated.timing(pulseAnim, {
          toValue: 1.2,
          duration: 1000,
          useNativeDriver: true,
        }),
        Animated.timing(pulseAnim, {
          toValue: 1,
          duration: 1000,
          useNativeDriver: true,
        }),
      ])
    ).start();
  };

  const startRecording = async () => {
    try {
      const path = await audioRecorderPlayer.startRecorder();
      setAudioPath(path);
      setIsRecording(true);
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
    }
  };

  const stopRecording = async () => {
    try {
      await audioRecorderPlayer.stopRecorder();
      setIsRecording(false);
      
      // Whisper APIë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcribedText = await voiceAPI.transcribeAudio(audioPath);
      
      // ì±„íŒ…ìœ¼ë¡œ ì „ì†¡
      await sendMessage(transcribedText, true);
      
      // ì±„íŒ… í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ê¸°
      navigation.goBack();
    } catch (error) {
      console.error('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨:', error);
    }
  };

  const cancelRecording = async () => {
    try {
      await audioRecorderPlayer.stopRecorder();
      setIsRecording(false);
      navigation.goBack();
    } catch (error) {
      console.error('ë…¹ìŒ ì·¨ì†Œ ì‹¤íŒ¨:', error);
    }
  };

  return (
    <View style={s.voiceContainer}>
      {/* í—¤ë” */}
      <View style={s.header}>
        <TouchableOpacity onPress={cancelRecording}>
          <Text>â†</Text>
        </TouchableOpacity>
        <Text style={s.headerTitle}>ëŒì‡ </Text>
        <View style={s.headerRight} />
      </View>

      {/* ìºë¦­í„° & ì• ë‹ˆë©”ì´ì…˜ */}
      <View style={s.voiceCenter}>
        <Animated.View
          style={[
            s.voiceCircle,
            { transform: [{ scale: pulseAnim }] }
          ]}
        >
          <View style={s.characterContainer}>
            {/* ìºë¦­í„° ì´ë¯¸ì§€ */}
          </View>
        </Animated.View>

        {/* ìŒì„± íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜ */}
        <View style={s.waveform}>
          <Text>ğŸµ</Text>
        </View>

        <Text style={s.voiceStatus}>
          {isRecording ? 'ì†ì£¼ê°€ ë“£ê³  ìˆì–´ìš”.' : 'ë§ì”€í•´ì£¼ì„¸ìš”'}
        </Text>
      </View>

      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <View style={s.voiceControls}>
        <TouchableOpacity style={s.controlButton}>
          <Text>ğŸ“¹</Text>
        </TouchableOpacity>

        <TouchableOpacity
          style={s.controlButton}
          onPress={isRecording ? stopRecording : startRecording}
        >
          <Text>{isRecording ? 'â¸' : 'ğŸ¤'}</Text>
        </TouchableOpacity>

        <TouchableOpacity style={s.controlButton} onPress={cancelRecording}>
          <Text>âœ•</Text>
        </TouchableOpacity>
      </View>
    </View>
  );
}